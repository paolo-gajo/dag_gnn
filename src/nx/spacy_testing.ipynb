{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency Matrix:\n",
      "[[0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.tokens import Doc\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "json_path = '/home/pgajo/Multitask-RFG/data/yamakata/efrc_ud.json'\n",
    "\n",
    "with open(json_path, 'r', encoding='utf8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "sample = data[0]\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "sent = sample['words']\n",
    "doc = nlp(Doc(nlp.vocab, sent))\n",
    "\n",
    "# Get the number of tokens\n",
    "num_tokens = len(doc)\n",
    "\n",
    "# Initialize an adjacency matrix of size num_tokens x num_tokens with zeros\n",
    "adj_matrix = np.zeros((num_tokens, num_tokens), dtype=int)\n",
    "\n",
    "# Populate the adjacency matrix based on dependencies with only `dobj` labels\n",
    "for token in doc:\n",
    "    if token.dep_ == 'dobj' and token.head != token:  # Only add for `dobj` dependencies\n",
    "        adj_matrix[token.head.i, token.i] = 1  # Edge from head to token for `dobj`\n",
    "\n",
    "# Print the adjacency matrix\n",
    "print(\"Adjacency Matrix:\")\n",
    "print(adj_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency Matrix with `dobj` dependencies:\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.tokens import Doc\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "json_path = '/home/pgajo/Multitask-RFG/data/yamakata/efrc_ud.json'\n",
    "\n",
    "with open(json_path, 'r', encoding='utf8') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "# Load the English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "sent = data[0]['words']\n",
    "doc = nlp(Doc(nlp.vocab, sent))\n",
    "\n",
    "# Get the number of tokens\n",
    "num_tokens = len(doc)\n",
    "\n",
    "# Initialize an adjacency matrix of size num_tokens x num_tokens with zeros\n",
    "adj_matrix = np.zeros((num_tokens, num_tokens), dtype=int)\n",
    "\n",
    "# Populate the adjacency matrix based on dependencies with only `dobj` labels\n",
    "for token in doc:\n",
    "    if token.dep_ == 'dobj' and token.head != token:  # Only add for `dobj` dependencies\n",
    "        adj_matrix[token.head.i, token.i] = 1  # Edge from head to token for `dobj`\n",
    "\n",
    "# Print the adjacency matrix\n",
    "print(\"Adjacency Matrix with `dobj` dependencies:\")\n",
    "print(adj_matrix.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 58)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data[0]['sent_indices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Example sent to parse\n",
    "sent = \"Apple's CEO Tim Cook visited the company's headquarters in Cupertino.\"\n",
    "\n",
    "# Parse the sent using spaCy\n",
    "doc = nlp(sent)\n",
    "print(doc)\n",
    "\n",
    "# Visualize the dependency tree with default settings\n",
    "displacy.render(doc, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Example sent to parse\n",
    "sent = [\"Prick\", \"the\", \"potatoes\", \"with\", \"a\", \"fork\", \"several\", \"times\", \",\", \"then\", \"rub\", \"potatoes\", \"with\", \"olive\", \"oil\", \",\", \"sprinkle\", \"with\", \"salt\", \"and\", \"wrap\", \"tightly\", \"in\", \"foil\", \".\", \"Place\", \"the\", \"potatoes\", \"into\", \"a\", \"slow\", \"cooker\", \",\", \"cover\", \",\", \"and\", \"cook\", \"on\", \"High\", \"for\", \"4\", \"1/2\", \"to\", \"5\", \"hours\", \",\", \"or\", \"on\", \"Low\", \"for\", \"7\", \"1/2\", \"to\", \"8\", \"hours\", \"until\", \"tender\", \".\"]\n",
    "# Tokenize the sent\n",
    "doc = \n",
    "\n",
    "\n",
    "# Get the number of tokens\n",
    "num_tokens = len(doc)\n",
    "\n",
    "# Initialize an empty matrix of size num_tokens x num_tokens with empty strings\n",
    "label_matrix = [[\"\" for _ in range(num_tokens)] for _ in range(num_tokens)]\n",
    "\n",
    "# Populate the label matrix based on dependencies\n",
    "for token in doc:\n",
    "    if token.head != token:  # Exclude root token pointing to itself\n",
    "        label_matrix[token.head.i][token.i] = token.dep_\n",
    "\n",
    "# Convert to a DataFrame for a cleaner display\n",
    "label_matrix_df = pd.DataFrame(label_matrix, columns=[token.text for token in doc], index=[token.text for token in doc])\n",
    "\n",
    "# Print the labeled adjacency matrix\n",
    "print(\"Labeled Adjacency Matrix:\")\n",
    "print(label_matrix_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Example instruction sent\n",
    "# sent = \"Prick the potatoes with a fork several times, then rub potatoes with olive oil, sprinkle with salt and wrap tightly in foil. Place the potatoes into a slow cooker, cover, and cook on High for 4 1/2 to 5 hours, or on Low for 7 1/2 to 8 hours until tender.\"\n",
    "sent = [\"Prick\", \"the\", \"potatoes\", \"with\", \"a\", \"fork\", \"several\", \"times\", \",\", \"then\", \"rub\", \"potatoes\", \"with\", \"olive\", \"oil\", \",\", \"sprinkle\", \"with\", \"salt\", \"and\", \"wrap\", \"tightly\", \"in\", \"foil\", \".\", \"Place\", \"the\", \"potatoes\", \"into\", \"a\", \"slow\", \"cooker\", \",\", \"cover\", \",\", \"and\", \"cook\", \"on\", \"High\", \"for\", \"4\", \"1/2\", \"to\", \"5\", \"hours\", \",\", \"or\", \"on\", \"Low\", \"for\", \"7\", \"1/2\", \"to\", \"8\", \"hours\", \"until\", \"tender\", \".\"]\n",
    "# Tokenize the sent\n",
    "doc = Doc(nlp.vocab, sent)\n",
    "doc = nlp(doc)\n",
    "\n",
    "# Extract tokens as a list of text\n",
    "tokens = [token.text for token in doc]\n",
    "print(len(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samsung",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
